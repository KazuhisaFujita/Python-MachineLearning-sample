{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_learning2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# データを識別してみよう。\n",
        "\n",
        "## 識別問題\n",
        "データは通常ベクトルの集合である。\n",
        "試しに、4個のベクトルを持つデータを作ってみる。"
      ],
      "metadata": {
        "id": "fsTpTxxsVa0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o4v1AoEfVXfT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = [[0.0, 0.0],\n",
        "     [0.0, 1.0],\n",
        "     [1.0, 0.0],\n",
        "     [1.0, 1.0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの識別では、データを構成するベクトルはそれぞれラベルを持っている。\n",
        "次にラベルデータを作ってみる。"
      ],
      "metadata": {
        "id": "aM63VTjlVaGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.array([0, 0, 0, 1])"
      ],
      "metadata": {
        "id": "qetXK_RiWNsP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "labelの各要素はそれぞれ、ベクトルに対応している。例えば、ベクトル(0, 0)にはラベル0がついている。このベクトルとラベルの対応を機械に覚えさせてみる。これを識別という。\n",
        "\n",
        "\n",
        "懸命な方は気づいたと思うが、このベクトルとラベルの対応関係はAND演算である。\n"
      ],
      "metadata": {
        "id": "lmw5qLGtWHUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ニューラルネットワーク\n",
        "識別問題を解く方法には様々ある。今後使うだろうニューラルネットワークでこの識別問題を解いてみよう。\n",
        "\n",
        "作成するニューラルネットワークは入力層、中間層、出力層の3層で構成する。\n",
        "中間層と出力層は2個のニューロンで構成され、それぞれのニューロンが2つ入力を持つ。\n",
        "中間層の活性化関数にReLu関数を用いる。\n",
        "出力はソフトマックス関数を用いる。\n",
        "\n",
        "$z_j = e^{y_j}/\\sum e^{y_j}$\n",
        "\n",
        "ニューラルネットワークを使うにはニューラルネットワーク用のライブラリを使う必要がある。今回はpytorchを使う。pytorchを使い前述のデータを識別するコードを示す。"
      ],
      "metadata": {
        "id": "GQmeu0JdWkOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        #ニューラルネットワークを作る\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear( 2, 2) #中間層 (入力の数、出力の数)\n",
        "        self.fc2 = nn.Linear( 2, 2) #出力層 (入力の数、出力の数)\n",
        "\n",
        "    def forward(self, input):\n",
        "        #ニューラルネットワークの計算をする\n",
        "        h = self.fc1(input) #中間層の計算\n",
        "        h = F.relu(h)       #活性化関数\n",
        "        h = self.fc2(h)     #出力層の計算\n",
        "        h = F.log_softmax(h, dim=1) #出力層の出力の計算\n",
        "        return h\n",
        "\n",
        "# ネットワークのオブジェクトを生成\n",
        "model = NeuralNetwork() \n",
        "# 最適化手法（学習方法）を設定\n",
        "optimizer = optim.SGD(model.parameters(),\n",
        "                      lr=0.5, momentum=0.99, nesterov=True) # 確率的勾配法\n",
        "\n",
        "epochs = 20 #学習回数\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  X_data = torch.tensor(x) #xをpytorchの形（tensor）に変換\n",
        "  y_true = torch.tensor(label) #labelをpytorchの形（tensor）に変換\n",
        "\n",
        "  y_outputs = model(X_data) #ニューラルネットワークの出力を計算\n",
        "  loss = F.nll_loss(y_outputs, y_true) #出力と正解との差を計算。\n",
        "  loss.backward()  #逆伝播\n",
        "  optimizer.step() #学習\n",
        "  print(\"学習回数: \", epoch, \"誤差: \", loss)\n",
        "\n",
        "X_data = torch.tensor(x) \n",
        "y_outputs = model(X_data)\n",
        "print(y_outputs)\n",
        "print(torch.argmax(y_outputs, axis=1))#最大値を持つ配列の要素番号を出力（要素番号=ラベル番号）"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnxzLSm4W53h",
        "outputId": "1e8a6c6f-3a79-4532-8c08-abad2126f8ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習回数:  0 誤差:  tensor(0.6849, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  1 誤差:  tensor(0.5906, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  2 誤差:  tensor(0.5683, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  3 誤差:  tensor(0.5779, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  4 誤差:  tensor(0.5839, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  5 誤差:  tensor(0.5733, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  6 誤差:  tensor(0.5710, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  7 誤差:  tensor(0.5591, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  8 誤差:  tensor(0.5412, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  9 誤差:  tensor(0.5195, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  10 誤差:  tensor(0.4916, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  11 誤差:  tensor(0.4531, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  12 誤差:  tensor(0.4084, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  13 誤差:  tensor(0.4406, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  14 誤差:  tensor(0.3683, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  15 誤差:  tensor(0.3458, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  16 誤差:  tensor(0.4341, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  17 誤差:  tensor(0.3352, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  18 誤差:  tensor(0.0879, grad_fn=<NllLossBackward0>)\n",
            "学習回数:  19 誤差:  tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
            "tensor([[-8.3446e-07, -1.3965e+01],\n",
            "        [-6.3006e-04, -7.3699e+00],\n",
            "        [-7.3955e-03, -4.9106e+00],\n",
            "        [-1.8616e+00, -1.6892e-01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([0, 0, 0, 1])\n"
          ]
        }
      ]
    }
  ]
}